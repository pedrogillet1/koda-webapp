import { GoogleGenerativeAI } from '@google/generative-ai';
import { Pinecone } from '@pinecone-database/pinecone';
import prisma from '../config/database';
import fileActionsService from './fileActions.service';
import { actionHistoryService } from './actionHistory.service';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DELETED DOCUMENT FILTER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Filter out deleted documents from Pinecone results
 */
async function filterDeletedDocuments(matches: any[], userId: string): Promise<any[]> {
  if (!matches || matches.length === 0) return [];

  // Get unique document IDs
  const documentIds = [...new Set(matches.map(m => m.metadata?.documentId).filter(Boolean))];

  if (documentIds.length === 0) return matches;

  // Query database for valid (non-deleted) documents
  const validDocuments = await prisma.document.findMany({
    where: {
      id: { in: documentIds },
      userId: userId,
      status: { not: 'deleted' },
    },
    select: { id: true },
  });

  const validDocumentIds = new Set(validDocuments.map(d => d.id));

  // Filter matches to only include valid documents
  const filtered = matches.filter(m => validDocumentIds.has(m.metadata?.documentId));

  if (filtered.length < matches.length) {
    console.log(`ğŸ—‘ï¸ [FILTER] Removed deleted documents: ${matches.length} â†’ ${filtered.length}`);
  }

  return filtered;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// HYBRID RAG SERVICE - Simple, Reliable, 95%+ Success Rate
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// ARCHITECTURE:
// 1. File Actions - Natural detection (create/rename/delete/move folder/file)
// 2. Comparisons - GUARANTEE multi-document retrieval
// 3. Meta-Queries - Answer from knowledge, don't search
// 4. Regular Queries - Standard RAG pipeline
//
// KEY FEATURES:
// - Real streaming (not fake word-by-word)
// - Fuzzy document matching (60% word match, no-spaces comparison)
// - Post-processing (remove emojis, fix "Next steps:", limit blank lines)
// - KODA persona (professional, friendly, bullet points, no emojis, bold)
//
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');
const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });
const embeddingModel = genAI.getGenerativeModel({ model: 'text-embedding-004' });

let pinecone: Pinecone | null = null;
let pineconeIndex: any = null;

// Initialize Pinecone
async function initializePinecone() {
  if (!pinecone) {
    pinecone = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY || '',
    });
    pineconeIndex = pinecone.index(process.env.PINECONE_INDEX_NAME || 'koda-gemini');
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MAIN ENTRY POINT - Streaming Answer Generation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export async function generateAnswerStream(
  userId: string,
  query: string,
  conversationId: string,
  onChunk: (chunk: string) => void,
  attachedDocumentId?: string
): Promise<{ sources: any[] }> {
  await initializePinecone();

  console.log('\nğŸ¯ [HYBRID RAG] Processing query:', query);
  console.log('ğŸ“ Attached document ID:', attachedDocumentId);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STEP 1: File Actions - Natural Detection AND EXECUTION
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const fileAction = await detectFileAction(query);
  if (fileAction) {
    console.log('ğŸ“ [FILE ACTION] Detected:', fileAction);
    await handleFileAction(userId, query, fileAction, onChunk);
    return { sources: [] }; // File actions don't have sources
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STEP 2: Comparisons - GUARANTEE Multi-Document Retrieval
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const comparison = await detectComparison(userId, query);
  if (comparison) {
    console.log('ğŸ”„ [COMPARISON] Detected:', comparison.documents);
    return await handleComparison(userId, query, comparison, onChunk);
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STEP 3: Meta-Queries - Answer from Knowledge
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (isMetaQuery(query)) {
    console.log('ğŸ’­ [META-QUERY] Detected');
    await handleMetaQuery(query, onChunk);
    return { sources: [] }; // Meta queries don't have sources
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STEP 4: Regular Queries - Standard RAG
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  console.log('ğŸ“š [REGULAR QUERY] Processing');
  return await handleRegularQuery(userId, query, conversationId, onChunk, attachedDocumentId);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FILE ACTION DETECTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function detectFileAction(query: string): Promise<string | null> {
  const lower = query.toLowerCase().trim();

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STAGE 1: Regex Pattern Matching (Fast Path)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  // Folder operations
  if (/(create|make|new|add).*folder/i.test(lower)) {
    return 'createFolder';
  }
  if (/(rename|change.*name).*folder/i.test(lower)) {
    return 'renameFolder';
  }
  if (/(delete|remove).*folder/i.test(lower)) {
    return 'deleteFolder';
  }
  if (/(move|relocate).*folder/i.test(lower)) {
    return 'moveFolder';
  }

  // File operations
  if (/(create|make|new|add).*file/i.test(lower)) {
    return 'createFile';
  }
  if (/(rename|change.*name).*file/i.test(lower)) {
    return 'renameFile';
  }
  if (/(delete|remove).*file/i.test(lower)) {
    return 'deleteFile';
  }
  if (/(move|relocate).*file/i.test(lower)) {
    return 'moveFile';
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STAGE 2: LLM Intent Detection (Fallback for natural queries)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  try {
    console.log('ğŸ¤– [FILE ACTION] No strict match, trying LLM intent detection...');

    // Dynamic import to avoid circular dependency
    const { llmIntentDetectorService } = await import('./llmIntentDetector.service');

    const intentResult = await llmIntentDetectorService.detectIntent(query);
    console.log('ğŸ¤– [FILE ACTION] LLM intent:', intentResult);

    // Map LLM intents to file actions
    const fileActionIntents: Record<string, string> = {
      'create_folder': 'createFolder',
      'move_files': 'moveFile',
      'rename_file': 'renameFile',
      'delete_file': 'deleteFile'
    };

    if (fileActionIntents[intentResult.intent] && intentResult.confidence > 0.7) {
      const action = fileActionIntents[intentResult.intent];
      console.log(`âœ… [FILE ACTION] LLM detected: ${action}`);
      return action;
    }

    console.log('âŒ [FILE ACTION] LLM confidence too low or not a file action');
  } catch (error) {
    console.error('âŒ [FILE ACTION] LLM intent detection failed:', error);
  }

  return null;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FILE ACTION EXECUTION - ACTUALLY EXECUTE ACTIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function handleFileAction(
  userId: string,
  query: string,
  actionType: string,
  onChunk: (chunk: string) => void
): Promise<void> {
  console.log(`ğŸ”§ [FILE ACTION] Executing: ${actionType}`);

  try {
    // âœ… FIX: Use fileActionsService.executeAction which handles nameâ†’ID lookup
    const result = await fileActionsService.executeAction(query, userId);

    // Stream the result to the user
    if (result.success) {
      onChunk(result.message);

      // TODO: Record action for undo (needs refactoring)
      // The executeAction doesn't return document/folder IDs needed for undo
    } else {
      onChunk(`Sorry, I couldn't complete that action: ${result.error || result.message}`);
    }

  } catch (error: any) {
    console.error('âŒ [FILE ACTION] Error:', error);
    onChunk(`Sorry, an error occurred while trying to execute that action: ${error.message}`);
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COMPARISON DETECTION - FUZZY MATCHING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function detectComparison(userId: string, query: string): Promise<{
  documents: string[];
  aspect?: string;
} | null> {
  const lower = query.toLowerCase();

  // Check for comparison keywords
  const comparisonPatterns = [
    /\bcompare\b/,
    /\bdifference(s)?\b/,
    /\bvs\b/,
    /\bversus\b/,
    /\band\b.*\band\b/,  // "doc1 and doc2"
  ];

  const hasComparisonKeyword = comparisonPatterns.some(pattern => pattern.test(lower));

  if (!hasComparisonKeyword) {
    return null;
  }

  // Extract document mentions with fuzzy matching
  const mentions = await extractDocumentMentions(userId, query);

  if (mentions.length >= 2) {
    console.log('âœ… [COMPARISON] Found documents:', mentions);
    return { documents: mentions };
  }

  console.log('âŒ [COMPARISON] Not enough documents found');
  return null;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FUZZY DOCUMENT MATCHING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function extractDocumentMentions(userId: string, query: string): Promise<string[]> {
  const queryLower = query.toLowerCase();

  // Get all user's documents
  const documents = await prisma.document.findMany({
    where: { userId },
    select: { id: true, filename: true },
  });

  console.log(`ğŸ“„ [FUZZY MATCH] Checking ${documents.length} documents`);

  const matches: string[] = [];

  for (const doc of documents) {
    if (isDocumentMentioned(queryLower, doc.filename)) {
      console.log(`âœ… [FUZZY MATCH] Found: ${doc.filename}`);
      matches.push(doc.id);
    }
  }

  return matches;
}

function isDocumentMentioned(queryLower: string, documentName: string): boolean {
  const docNameLower = documentName.toLowerCase();

  // Remove file extensions for matching
  const docNameNoExt = docNameLower.replace(/\.(pdf|docx?|txt|xlsx?|pptx?|csv)$/i, '');

  // Split into words
  const docWords = docNameNoExt.split(/\s+/).filter(w => w.length > 0);

  // Check if 60% of words are present
  const threshold = Math.ceil(docWords.length * 0.6);
  let matchCount = 0;

  for (const word of docWords) {
    // Remove spaces and special chars for flexible matching
    const cleanWord = word.replace(/[^a-z0-9]/g, '');
    const cleanQuery = queryLower.replace(/[^a-z0-9\s]/g, '');

    if (cleanQuery.includes(cleanWord)) {
      matchCount++;
    }
  }

  const matched = matchCount >= threshold;

  if (matched) {
    console.log(`  âœ“ "${documentName}" matched: ${matchCount}/${docWords.length} words (threshold: ${threshold})`);
  }

  return matched;
}

/**
 * Extract potential document names from query
 * Examples:
 * - "what is pedro1 about" â†’ ["pedro1"]
 * - "compare pedro1 and pedro2" â†’ ["pedro1", "pedro2"]
 * - "tell me about the marketing report" â†’ ["marketing", "report"]
 */
function extractDocumentNames(query: string): string[] {
  const words = query.toLowerCase()
    .replace(/[^\w\s]/g, ' ')  // Remove punctuation
    .split(/\s+/)
    .filter(w => w.length > 2);  // Ignore short words like "is", "me"

  console.log('ğŸ” [EXTRACT] All words:', words);

  // Remove common question words AND file extensions
  const stopWords = new Set([
    'what', 'tell', 'about', 'the', 'and', 'compare', 'between',
    'show', 'find', 'get', 'give', 'how', 'why', 'when', 'where',
    'can', 'you', 'please', 'summary', 'summarize', 'does', 'talk',
    'pdf', 'doc', 'docx', 'txt', 'xlsx', 'xls', 'pptx', 'ppt', 'csv'
  ]);

  const result = words.filter(w => !stopWords.has(w));
  console.log('ğŸ” [EXTRACT] After filtering stop words:', result);
  return result;
}

/**
 * Find documents matching potential names using fuzzy matching
 */
async function findDocumentsByName(
  userId: string,
  potentialNames: string[]
): Promise<string[]> {
  if (potentialNames.length === 0) return [];

  console.log('ğŸ” [DOC SEARCH] Looking for documents matching:', potentialNames);

  try {
    // Get all user's documents from database
    const allDocs = await prisma.document.findMany({
      where: { userId, status: { not: 'deleted' } },
      select: { id: true, filename: true },
    });

    console.log(`ğŸ“„ [DOC SEARCH] Checking ${allDocs.length} documents`);

    // Fuzzy match against potential names
    const matchedDocIds: string[] = [];

    for (const doc of allDocs) {
      const docLower = doc.filename.toLowerCase();
      const docWithoutExt = docLower.replace(/\.(pdf|docx?|txt|xlsx?|pptx?|csv)$/i, '');

      console.log(`ğŸ“„ [DOC SEARCH] Checking document: "${doc.filename}" (lower: "${docLower}", without ext: "${docWithoutExt}")`);

      for (const potentialName of potentialNames) {
        const match1 = docLower.includes(potentialName);
        const match2 = potentialName.includes(docWithoutExt);
        const match3 = docWithoutExt.includes(potentialName);

        console.log(`  ğŸ” Testing "${potentialName}": docLower.includes="${match1}", potentialName.includes(docWithoutExt)="${match2}", docWithoutExt.includes="${match3}"`);

        // Check if document name contains the potential name OR vice versa
        if (match1 || match2 || match3) {
          matchedDocIds.push(doc.id);
          console.log(`  âœ… [DOC SEARCH] MATCHED "${potentialName}" â†’ "${doc.filename}"`);
          break;
        }
      }
    }

    return matchedDocIds;

  } catch (error) {
    console.error('âŒ [DOC SEARCH] Error:', error);
    return [];
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COMPARISON HANDLER - GUARANTEE Multi-Document Retrieval
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function handleComparison(
  userId: string,
  query: string,
  comparison: { documents: string[] },
  onChunk: (chunk: string) => void
): Promise<{ sources: any[] }> {
  console.log('ğŸ”„ [COMPARISON] Retrieving content for documents:', comparison.documents);

  // GUARANTEE: Search each document separately
  const allChunks: any[] = [];

  for (const docId of comparison.documents) {
    console.log(`  ğŸ“„ Searching document: ${docId}`);

    // Generate embedding for query
    const embeddingResult = await embeddingModel.embedContent(query);
    const queryEmbedding = embeddingResult.embedding.values;

    // Search this specific document
    const rawResults = await pineconeIndex.query({
      vector: queryEmbedding,
      topK: 5,
      filter: { documentId: docId },
      includeMetadata: true,
    });

    // Filter out deleted documents
    const filteredMatches = await filterDeletedDocuments(rawResults.matches || [], userId);

    console.log(`  âœ… Found ${filteredMatches.length} chunks for ${docId}`);

    if (filteredMatches.length > 0) {
      allChunks.push(...filteredMatches);
    }
  }

  console.log(`âœ… [COMPARISON] Total chunks retrieved: ${allChunks.length}`);

  // Build context from all chunks
  const context = allChunks
    .map((match: any) => {
      const meta = match.metadata || {};
      // âœ… FIX: Use correct field names from Pinecone (content, filename, page)
      return `[Document: ${meta.filename || 'Unknown'}, Page: ${meta.page || 'N/A'}]\n${meta.content || ''}`;
    })
    .join('\n\n---\n\n');

  // Build sources array from all chunks
  const sources = allChunks.map((match: any) => ({
    documentName: match.metadata?.filename || 'Unknown',
    pageNumber: match.metadata?.page || 0,
    score: match.score || 0
  }));

  // Generate comparison answer
  const systemPrompt = `You are KODA, a professional AI assistant helping users understand their documents.

The user wants to compare multiple documents. Here's the relevant content from each:

${context}

FORMATTING INSTRUCTIONS (CRITICAL - FOLLOW EXACTLY):
- Between bullet points: Use SINGLE newline only (no blank lines)
- Before "Next step:" section: Use ONE blank line
- Compare the documents clearly and objectively
- Bold key differences with **text**
- Cite specific sources with document names and page numbers
- Be thorough but concise
- NO emojis

User query: "${query}"`;

  await streamLLMResponse(systemPrompt, '', onChunk);
  return { sources };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// META-QUERY DETECTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function isMetaQuery(query: string): boolean {
  const lower = query.toLowerCase().trim();

  const metaPatterns = [
    /^(hi|hey|hello|greetings)/,
    /what (can|do) you (do|help)/,
    /who are you/,
    /what are you/,
    /how (do|can) (i|you)/,
    /tell me about (yourself|koda)/,
  ];

  return metaPatterns.some(pattern => pattern.test(lower));
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// META-QUERY HANDLER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function handleMetaQuery(query: string, onChunk: (chunk: string) => void): Promise<void> {
  const prompt = `You are KODA, a professional AI document assistant.

WHAT YOU CAN DO:
- Answer questions about uploaded documents
- Compare multiple documents
- Search across all documents
- Summarize content
- Extract specific information
- Help with document organization (create/rename/delete folders and files)

FORMATTING INSTRUCTIONS (CRITICAL - FOLLOW EXACTLY):
- Between bullet points: Use SINGLE newline only (no blank lines)
- Before "Next step:" section: Use ONE blank line
- Professional, friendly tone
- Bold key features with **text**
- NO emojis

User query: "${query}"

Respond naturally and helpfully.`;

  return streamLLMResponse(prompt, '', onChunk);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// REGULAR QUERY HANDLER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function handleRegularQuery(
  userId: string,
  query: string,
  conversationId: string,
  onChunk: (chunk: string) => void,
  attachedDocumentId?: string
): Promise<void> {
  console.log('ğŸ“š [REGULAR QUERY] Starting RAG pipeline');

  // Generate query embedding
  const embeddingResult = await embeddingModel.embedContent(query);
  const queryEmbedding = embeddingResult.embedding.values;

  // Build search filter
  const filter: any = { userId };

  // âœ… NEW: Try to detect document names in query
  let searchResults;

  if (attachedDocumentId) {
    // Use attached document if provided
    filter.documentId = attachedDocumentId;
    console.log('ğŸ“ [REGULAR QUERY] Filtering by attached document:', attachedDocumentId);

    const rawResults = await pineconeIndex.query({
      vector: queryEmbedding,
      topK: 10,
      filter,
      includeMetadata: true,
    });

    const filteredMatches = await filterDeletedDocuments(rawResults.matches || [], userId);
    searchResults = { matches: filteredMatches };
  } else {
    // âœ… NEW: Try to find documents by name
    const potentialNames = extractDocumentNames(query);
    const matchedDocs = await findDocumentsByName(userId, potentialNames);

    if (matchedDocs.length > 0) {
      console.log(`âœ… [REGULAR QUERY] Found ${matchedDocs.length} documents by name`);

      // Search within matched documents
      const allResults = [];

      for (const docId of matchedDocs) {
        const docFilter = { userId, documentId: docId };
        const rawResults = await pineconeIndex.query({
          vector: queryEmbedding,
          topK: 5,
          filter: docFilter,
          includeMetadata: true,
        });

        const filteredMatches = await filterDeletedDocuments(rawResults.matches || [], userId);
        allResults.push(...filteredMatches);
      }

      searchResults = { matches: allResults };
    } else {
      // Fall back to regular vector search
      console.log('ğŸ“Š [REGULAR QUERY] No document names detected, using vector search');
      const rawResults = await pineconeIndex.query({
        vector: queryEmbedding,
        topK: 10,
        filter,
        includeMetadata: true,
      });

      const filteredMatches = await filterDeletedDocuments(rawResults.matches || [], userId);
      searchResults = { matches: filteredMatches };
    }
  }

  console.log(`âœ… [REGULAR QUERY] Found ${searchResults.matches?.length || 0} relevant chunks`);

  // ğŸ› DEBUG: Log first chunk to see what Pinecone is returning
  if (searchResults.matches && searchResults.matches.length > 0) {
    console.log('ğŸ› [DEBUG] First chunk sample:', JSON.stringify(searchResults.matches[0], null, 2));
  }

  // Build context
  const context = searchResults.matches
    ?.map((match: any) => {
      const meta = match.metadata || {};
      // âœ… FIX: Use correct field names from Pinecone (content, filename, page)
      return `[Source: ${meta.filename || 'Unknown'}, Page: ${meta.page || 'N/A'}]\n${meta.content || ''}`;
    })
    .join('\n\n---\n\n') || '';

  console.log(`ğŸ“ [CONTEXT] Length: ${context.length} chars`);
  console.log(`ğŸ“ [CONTEXT] Preview: ${context.substring(0, 200)}...`);
  console.log(`ğŸ› [DEBUG] Full context (first 500 chars): ${context.substring(0, 500)}`);

  // Build sources array from search results
  const sources = searchResults.matches?.map((match: any) => ({
    documentName: match.metadata?.filename || 'Unknown',
    pageNumber: match.metadata?.page || 0,
    score: match.score || 0
  })) || [];

  // System prompt
  const systemPrompt = `You are KODA, a professional AI assistant helping users understand their documents.

RELEVANT CONTENT FROM USER'S DOCUMENTS:
${context}

FORMATTING INSTRUCTIONS (CRITICAL - FOLLOW EXACTLY):
- Between bullet points: Use SINGLE newline only (no blank lines)
- Before "Next step:" section: Use ONE blank line
- Answer based on the provided content
- Bold key information with **text**
- Cite sources with document names and page numbers
- If the content doesn't answer the question, say so honestly
- NO emojis

User query: "${query}"`;

  await streamLLMResponse(systemPrompt, '', onChunk);
  return { sources };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// REAL STREAMING - Gemini generateContentStream
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function streamLLMResponse(
  systemPrompt: string,
  context: string,
  onChunk: (chunk: string) => void
): Promise<void> {
  console.log('ğŸŒŠ [STREAMING] Starting real stream');

  const fullPrompt = context ? `${systemPrompt}\n\nContext:\n${context}` : systemPrompt;

  let fullAnswer = '';

  try {
    const result = await model.generateContentStream(fullPrompt);

    // âœ… REAL STREAMING: Stream chunks in real-time with spacing fixes
    for await (const chunk of result.stream) {
      const text = chunk.text();
      fullAnswer += text;

      // Apply spacing fixes to each chunk
      const processedChunk = text
        // Ensure one blank line before any bullet list
        .replace(/(:)\n([â€¢\-\*])/g, '$1\n\n$2')
        // Remove blank lines before bullets (â€¢, -, or *)
        .replace(/\n\n([â€¢\-\*])/g, '\n$1')
        // Collapse 3+ newlines into one blank line (2 \n)
        .replace(/\n\n\n+/g, '\n\n')
        // Ensure one blank line before "Next step:"
        .replace(/\n(?=Next step:)/g, '\n\n')
        // Fix quadruple asterisks
        .replace(/\*\*\*\*/g, '**')
        // Remove emojis
        .replace(/[\u{1F300}-\u{1F9FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu, '')
        .replace(/[âŒâœ…ğŸ”ğŸ“ğŸ“ŠğŸ“„ğŸ¯âš ï¸ğŸ’¡ğŸš¨]/g, '');

      onChunk(processedChunk);
    }

    console.log('âœ… [STREAMING] Complete. Total chars:', fullAnswer.length);

  } catch (error: any) {
    console.error('âŒ [STREAMING] Error:', error);
    onChunk('I apologize, but I encountered an error generating the response. Please try again.');
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// POST-PROCESSING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function postProcessAnswer(answer: string): string {
  let processed = answer;

  // Remove emojis
  processed = processed.replace(/[\u{1F300}-\u{1F9FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu, '');
  processed = processed.replace(/[âŒâœ…ğŸ”ğŸ“ğŸ“ŠğŸ“„ğŸ¯âš ï¸ğŸ’¡ğŸš¨]/g, '');

  // Fix excessive blank lines - CRITICAL: Use \n\n\n+ to preserve paragraph breaks!
  // Replace 3+ newlines (2+ blank lines) with 2 newlines (1 blank line)
  processed = processed.replace(/\n\n\n+/g, '\n\n');

  // Fix quadruple asterisks
  processed = processed.replace(/\*\*\*\*/g, '**');

  // Fix "Next steps:" to "Next step:"
  processed = processed.replace(/Next steps:/gi, 'Next step:');

  // Trim
  processed = processed.trim();

  return processed;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// LEGACY COMPATIBILITY - Non-streaming version (fallback)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export async function generateAnswer(
  userId: string,
  query: string,
  conversationId: string,
  attachedDocumentId?: string
): Promise<{ answer: string; sources: any[] }> {
  console.log('âš ï¸  [LEGACY] Using non-streaming method (deprecated)');

  let fullAnswer = '';
  const sources: any[] = [];

  await generateAnswerStream(
    userId,
    query,
    conversationId,
    (chunk) => {
      fullAnswer += chunk;
    },
    attachedDocumentId
  );

  return {
    answer: fullAnswer,
    sources, // TODO: Extract sources from context
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BACKWARDS COMPATIBILITY WRAPPER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Old signature: (userId, query, conversationId, answerLength, documentId, onChunk)
// Returns: { answer: string, sources: any[] }
// New signature: (userId, query, conversationId, onChunk, attachedDocumentId)
// Returns: void (streams only)
export async function generateAnswerStreaming(
  userId: string,
  query: string,
  conversationId: string,
  answerLength: 'short' | 'medium' | 'summary' | 'long',
  documentId: string | null | undefined,
  onChunk: (chunk: string) => void
): Promise<{ answer: string; sources: any[] }> {
  // Accumulate chunks to build final answer
  let fullAnswer = '';

  // Wrap the onChunk callback to accumulate chunks
  const accumulatingCallback = (chunk: string) => {
    fullAnswer += chunk;
    onChunk(chunk); // Still call the original callback for streaming
  };

  // Call the new hybrid RAG function
  await generateAnswerStream(
    userId,
    query,
    conversationId,
    accumulatingCallback,
    documentId || undefined
  );

  // Return result object for backwards compatibility
  return {
    answer: fullAnswer,
    sources: [], // Hybrid RAG doesn't provide sources yet
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DEFAULT EXPORT (for backward compatibility with default imports)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export default {
  generateAnswer,
  generateAnswerStream,
  generateAnswerStreaming,
};

