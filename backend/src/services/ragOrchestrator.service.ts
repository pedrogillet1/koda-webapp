// @ts-nocheck
/**
 * RAG Orchestrator - Main Entry Point for All Queries
 *
 * Replaces: rag.service.ts (10,824 lines â†’ 300 lines)
 *
 * This is the ONLY public API for answering queries.
 * All other services are internal implementation details.
 *
 * Flow:
 * 1. Check L1/L2 cache
 * 2. Detect intent & answer type
 * 3. Route to appropriate handler
 * 4. Cache result & return
 */

import { detectAnswerType, type IntentDetectionResult } from './kodaIntentEngine.service';
import { detectLanguage } from './languageDetection.service';
import { KodaRetrievalEngine, type RetrievalResult } from './kodaRetrievalEngine.service';
import { KodaMemoryEngine } from './kodaMemoryEngine.service';
import { buildContext } from './contextManager.service';
import { generateAdaptiveAnswer, type GeneratedAnswer } from './answerGenerator.service';
import { formatAnswer, type FormattedAnswer } from './answerFormatter.service';
import { validateAnswer, type ValidationResult } from './answerValidator.service';
import { KodaStreamingController } from './kodaStreamingController.service';
import crypto from 'crypto';
import { withBudget, getBudgetForQueryType, getAdaptiveBudget } from '../utils/budgetEnforcer';
import { recordMetric, recordCacheEvent, recordQueryType } from './performanceMonitor.service';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// L1 CACHE: In-Memory (fastest, ~1ms)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface CacheEntry {
  result: QueryResult;
  timestamp: number;
}

// L1: In-memory cache (Map for fast lookups)
const L1_CACHE = new Map<string, CacheEntry>();
const L1_TTL = 5 * 60 * 1000; // 5 minutes
const L1_MAX_SIZE = 500; // Max entries

// L1 cache stats for monitoring
const cacheStats = {
  l1Hits: 0,
  l1Misses: 0,
  l2Hits: 0,
  l2Misses: 0,
};

/**
 * Generate cache key from query + userId
 */
function generateCacheKey(query: string, userId: string): string {
  const normalized = query.toLowerCase().trim();
  return crypto.createHash('md5').update(`${userId}:${normalized}`).digest('hex');
}

/**
 * Check L1 cache (in-memory)
 */
function checkL1Cache(key: string): QueryResult | null {
  const startTime = Date.now();
  const entry = L1_CACHE.get(key);

  if (entry && (Date.now() - entry.timestamp) < L1_TTL) {
    cacheStats.l1Hits++;
    const latency = Date.now() - startTime;
    recordMetric('CACHE', 'L1_CACHE', latency, { hit: true });
    recordCacheEvent('l1', true);
    console.log(`âœ… [L1 CACHE HIT] Key: ${key.substring(0, 8)}... (${cacheStats.l1Hits} total hits, ${latency}ms)`);
    return entry.result;
  }

  if (entry) {
    // Expired, remove it
    L1_CACHE.delete(key);
  }

  cacheStats.l1Misses++;
  recordCacheEvent('l1', false);
  return null;
}

/**
 * Set L1 cache entry
 */
function setL1Cache(key: string, result: QueryResult): void {
  // Evict oldest entries if cache is full
  if (L1_CACHE.size >= L1_MAX_SIZE) {
    const oldestKey = L1_CACHE.keys().next().value;
    L1_CACHE.delete(oldestKey);
  }

  L1_CACHE.set(key, {
    result,
    timestamp: Date.now(),
  });
}

/**
 * Get cache statistics
 */
export function getCacheStats() {
  const l1Total = cacheStats.l1Hits + cacheStats.l1Misses;
  const l2Total = cacheStats.l2Hits + cacheStats.l2Misses;

  return {
    l1: {
      hits: cacheStats.l1Hits,
      misses: cacheStats.l1Misses,
      hitRate: l1Total > 0 ? ((cacheStats.l1Hits / l1Total) * 100).toFixed(2) + '%' : '0%',
      size: L1_CACHE.size,
      maxSize: L1_MAX_SIZE,
    },
    l2: {
      hits: cacheStats.l2Hits,
      misses: cacheStats.l2Misses,
      hitRate: l2Total > 0 ? ((cacheStats.l2Hits / l2Total) * 100).toFixed(2) + '%' : '0%',
    },
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ANSWER TYPES THAT SHOULD NOT BE CACHED
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const NON_CACHEABLE_TYPES = new Set([
  'DOC_COUNT',  // Always fetch fresh count
  'FILE_NAVIGATION',
  'FOLDER_NAVIGATION',
]);

export interface QueryOptions {
  query: string;
  userId: string;
  conversationId?: string;
  streamingCallback?: (chunk: string) => void;
}

export interface QueryResult {
  answer: string;
  answerType: string;
  language: string;
  documentReferences: Array<{ id: string; name: string; displayTitle?: string }>;
  metadata: {
    retrievalTime?: number;
    generationTime?: number;
    totalTime: number;
    tokensUsed?: number;
    model?: string;
    validationScore?: number;
  };
}

/**
 * Main entry point: Answer any query
 *
 * Performance targets:
 * - ULTRA_FAST_GREETING: < 50ms
 * - DOC_COUNT: < 500ms
 * - APP_HELP: < 1.5s
 * - CALCULATION: < 3s
 * - RAG queries: < 5s
 * - Cache hits: < 5ms
 */
export async function answerQuery(options: QueryOptions): Promise<QueryResult> {
  const startTime = Date.now();
  const { query, userId, conversationId, streamingCallback } = options;

  console.log(`\n${'â•'.repeat(60)}`);
  console.log(`ğŸš€ [RAG] Query: "${query.substring(0, 50)}..."`);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 0: Cache Check (L1 in-memory â†’ L2 Redis)
  // Target: < 5ms for cache hit
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const cacheKey = generateCacheKey(query, userId);

  // Check L1 (in-memory) first - fastest
  const l1Cached = checkL1Cache(cacheKey);
  if (l1Cached && !streamingCallback) {
    console.log(`âš¡ [CACHE] L1 hit in ${Date.now() - startTime}ms`);
    console.log(`${'â•'.repeat(60)}\n`);
    return {
      ...l1Cached,
      metadata: {
        ...l1Cached.metadata,
        totalTime: Date.now() - startTime,
        cacheHit: 'L1',
      },
    };
  }

  // TODO: L2 Redis cache check would go here
  // const l2Cached = await checkL2Cache(cacheKey);
  // if (l2Cached && !streamingCallback) { ... }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 1: Language & Intent Detection (< 10ms)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  const language = detectLanguage(query);
  const intent = await detectAnswerType({
    query,
    userId,
    conversationHistory: conversationId ? await getConversationHistory(conversationId) : [],
  });

  console.log(`ğŸ¯ [INTENT] ${intent.answerType} (confidence: ${(intent.confidence * 100).toFixed(0)}%)`);

  // Record query type for monitoring
  recordQueryType(intent.answerType);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 2: Route to appropriate handler
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  let result: QueryResult;

  switch (intent.answerType) {
    case 'ULTRA_FAST_GREETING':
      console.log(`âš¡ [ROUTE] â†’ Greeting handler`);
      result = await handleGreeting(query, language, startTime);
      break;

    case 'DOC_COUNT':
      console.log(`ğŸ“Š [ROUTE] â†’ Doc count handler`);
      result = await handleDocCount(userId, language, startTime);
      break;

    case 'FILE_NAVIGATION':
    case 'FOLDER_NAVIGATION':
      console.log(`ğŸ“ [ROUTE] â†’ Navigation handler`);
      result = await handleNavigation(query, userId, intent, language, startTime);
      break;

    case 'APP_HELP':
      console.log(`â“ [ROUTE] â†’ App help handler`);
      result = await handleAppHelp(query, language, startTime);
      break;

    case 'CALCULATION':
      console.log(`ğŸ§® [ROUTE] â†’ Calculation handler`);
      result = await handleCalculation(query, userId, intent, language, startTime, streamingCallback);
      break;

    case 'MEMORY':
    case 'SINGLE_DOC_RAG':
    case 'CROSS_DOC_RAG':
    case 'COMPLEX_ANALYSIS':
    case 'STANDARD_QUERY':
    default:
      console.log(`ğŸ“š [ROUTE] â†’ RAG handler (${intent.answerType})`);
      result = await handleRAG(query, userId, conversationId, intent, language, startTime, streamingCallback);
      break;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 3: Cache result (if cacheable)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  if (!NON_CACHEABLE_TYPES.has(intent.answerType) && !streamingCallback) {
    setL1Cache(cacheKey, result);
    console.log(`ğŸ’¾ [CACHE] Stored in L1 (key: ${cacheKey.substring(0, 8)}...)`);
  }

  // Record total request metric for monitoring
  recordMetric('RAG', 'TOTAL_REQUEST', result.metadata.totalTime, {
    answerType: result.answerType,
    language: result.language,
    cacheHit: false,
  });

  console.log(`âœ… [COMPLETE] ${result.metadata.totalTime}ms (type: ${result.answerType})`);
  console.log(`${'â•'.repeat(60)}\n`);

  return result;
}

/**
 * Handle greeting (< 50ms)
 */
async function handleGreeting(query: string, language: string, startTime: number): Promise<QueryResult> {
  const greetings: Record<string, string> = {
    en: `Hello! I'm Koda, your AI assistant for document analysis. I can help you find information in your documents, answer questions, and analyze data.

What would you like to know?`,
    
    pt: `OlÃ¡! Sou o Koda, seu assistente de IA para anÃ¡lise de documentos. Posso ajudÃ¡-lo a encontrar informaÃ§Ãµes nos seus documentos, responder perguntas e analisar dados.

O que gostaria de saber?`,

    es: `Â¡Hola! Soy Koda, tu asistente de IA para anÃ¡lisis de documentos. Puedo ayudarte a encontrar informaciÃ³n en tus documentos, responder preguntas y analizar datos.

Â¿QuÃ© te gustarÃ­a saber?`,
  };

  return {
    answer: greetings[language] || greetings.en,
    answerType: 'ULTRA_FAST_GREETING',
    language,
    documentReferences: [],
    metadata: {
      totalTime: Date.now() - startTime,
    },
  };
}

/**
 * Handle document count (< 500ms)
 */
async function handleDocCount(userId: string, language: string, startTime: number): Promise<QueryResult> {
  // TODO: Implement actual document count from database
  const count = await getDocumentCount(userId);

  const answers: Record<string, string> = {
    en: `You have **${count} documents** in your workspace.

Would you like to see a list of your documents or search for something specific?`,
    
    pt: `VocÃª tem **${count} documentos** no seu workspace.

Gostaria de ver a lista dos seus documentos ou buscar algo especÃ­fico?`,

    es: `Tienes **${count} documentos** en tu workspace.

Â¿Te gustarÃ­a ver la lista de tus documentos o buscar algo especÃ­fico?`,
  };

  return {
    answer: answers[language] || answers.en,
    answerType: 'DOC_COUNT',
    language,
    documentReferences: [],
    metadata: {
      totalTime: Date.now() - startTime,
    },
  };
}

/**
 * Handle file/folder navigation (< 500ms)
 */
async function handleNavigation(
  query: string,
  userId: string,
  intent: IntentDetectionResult,
  language: string,
  startTime: number
): Promise<QueryResult> {
  // TODO: Import and use navigationOrchestrator
  // const { handleFileNavigation, handleFolderNavigation } = await import('./navigationOrchestrator.service');
  
  // Placeholder
  return {
    answer: 'Navigation handler not yet implemented',
    answerType: intent.answerType,
    language,
    documentReferences: [],
    metadata: {
      totalTime: Date.now() - startTime,
    },
  };
}

/**
 * Handle app help (< 1.5s)
 */
async function handleAppHelp(query: string, language: string, startTime: number): Promise<QueryResult> {
  // TODO: Import and use appHelpEngine
  // const { getAppHelp } = await import('./appHelpEngine.service');
  
  // Placeholder
  return {
    answer: 'App help handler not yet implemented',
    answerType: 'APP_HELP',
    language,
    documentReferences: [],
    metadata: {
      totalTime: Date.now() - startTime,
    },
  };
}

/**
 * Handle calculation (< 3s)
 */
async function handleCalculation(
  query: string,
  userId: string,
  intent: IntentDetectionResult,
  language: string,
  startTime: number,
  streamingCallback?: (chunk: string) => void
): Promise<QueryResult> {
  // TODO: Import and use calculationEngine
  // const { calculate } = await import('./calculationEngine.service');
  
  // Placeholder
  return {
    answer: 'Calculation handler not yet implemented',
    answerType: 'CALCULATION',
    language,
    documentReferences: [],
    metadata: {
      totalTime: Date.now() - startTime,
    },
  };
}

/**
 * Handle RAG queries (1.5s - 5s)
 * Includes budget enforcement with fallback
 */
async function handleRAG(
  query: string,
  userId: string,
  conversationId: string | undefined,
  intent: IntentDetectionResult,
  language: string,
  startTime: number,
  streamingCallback?: (chunk: string) => void
): Promise<QueryResult> {

  // Get budget for this query type (with adaptive adjustment)
  const baseBudget = getBudgetForQueryType(intent.answerType);
  const adaptiveBudget = getAdaptiveBudget(`RAG_${intent.answerType}`, baseBudget);

  console.log(`â±ï¸ [BUDGET] ${intent.answerType}: ${adaptiveBudget}ms (base: ${baseBudget}ms)`);

  // Fallback response for timeout
  const fallbackResponse = (): QueryResult => {
    const fallbackAnswers: Record<string, string> = {
      en: `I'm taking longer than expected to process your question. Please try again with a more specific query, or try asking about a specific document.`,
      pt: `Estou demorando mais do que o esperado para processar sua pergunta. Por favor, tente novamente com uma consulta mais especÃ­fica, ou pergunte sobre um documento especÃ­fico.`,
      es: `Estoy tardando mÃ¡s de lo esperado en procesar tu pregunta. Por favor, intÃ©ntalo de nuevo con una consulta mÃ¡s especÃ­fica, o pregunta sobre un documento especÃ­fico.`,
    };

    return {
      answer: fallbackAnswers[language] || fallbackAnswers.en,
      answerType: 'TIMEOUT_FALLBACK',
      language,
      documentReferences: [],
      metadata: {
        totalTime: Date.now() - startTime,
        budgetExceeded: true,
      },
    };
  };

  // Execute RAG with budget enforcement (skip for streaming - can't timeout streams)
  if (!streamingCallback) {
    const budgetResult = await withBudget(
      () => executeRAG(query, userId, conversationId, intent, language, startTime, undefined),
      {
        targetLatency: adaptiveBudget,
        context: `RAG_${intent.answerType}`,
        onBudgetWarning: () => {
          console.warn(`âš ï¸ [RAG] Query approaching budget limit`);
        },
        onBudgetExceeded: async () => {
          console.error(`ğŸ”´ [RAG] Budget exceeded, using fallback`);
          return fallbackResponse();
        },
      }
    );

    if (budgetResult.success && budgetResult.result) {
      return budgetResult.result;
    }

    return fallbackResponse();
  }

  // Streaming queries - execute directly (can't enforce budget on streams)
  return executeRAG(query, userId, conversationId, intent, language, startTime, streamingCallback);
}

/**
 * Execute RAG pipeline (internal)
 */
async function executeRAG(
  query: string,
  userId: string,
  conversationId: string | undefined,
  intent: IntentDetectionResult,
  language: string,
  startTime: number,
  streamingCallback?: (chunk: string) => void
): Promise<QueryResult> {
  // Step 1: Retrieval (if needed)
  let retrievalResult: RetrievalResult | null = null;
  let retrievalTime = 0;

  if (intent.requiresRetrieval) {
    const retrievalEngine = new KodaRetrievalEngine();
    retrievalResult = await retrievalEngine.retrieve(query, userId, {
      topK: 10,
      method: 'auto',
      rerank: true,
    });
    retrievalTime = retrievalResult.retrievalTime;
  }

  // Step 2: Memory (if needed)
  let memoryContext = '';

  if (intent.requiresMemory && conversationId) {
    const memoryEngine = new KodaMemoryEngine();
    const memory = await memoryEngine.getRelevantMemory({
      conversationId,
      query,
      maxTokens: 2000,
    });
    memoryContext = memory.context;
  }

  // Step 3: Build context
  const context = await buildContext({
    query,
    memoryContext,
    retrievedChunks: retrievalResult?.chunks || [],
    answerType: intent.answerType,
    languageCode: language,
  });

  // Step 4: Generate answer
  const generated = await generateAdaptiveAnswer({
    query,
    context: context.finalContext,
    languageCode: language,
    answerType: intent.answerType,
    streamingCallback,
  });

  // Step 5: Format answer
  const documentMap = buildDocumentMap(retrievalResult?.chunks || []);
  const formatted = formatAnswer({
    rawAnswer: generated.text,
    documentMap,
    languageCode: language,
  });

  // Step 6: Validate answer
  const validation = validateAnswer({
    answer: formatted.text,
    query,
    context: context.finalContext,
    answerType: intent.answerType,
    languageCode: language,
    documentReferences: formatted.documentReferences,
  });

  // Step 7: Regenerate if needed (max 1 retry)
  let finalAnswer = formatted.text;
  let finalValidation = validation;

  if (validation.shouldRegenerate && !streamingCallback) {
    console.log(`[RAG] Regenerating due to validation issues (score: ${validation.score})`);
    
    const regenerated = await generateAdaptiveAnswer({
      query,
      context: context.finalContext,
      languageCode: language,
      answerType: intent.answerType,
    });

    const reformatted = formatAnswer({
      rawAnswer: regenerated.text,
      documentMap,
      languageCode: language,
    });

    finalAnswer = reformatted.text;
    
    finalValidation = validateAnswer({
      answer: reformatted.text,
      query,
      context: context.finalContext,
      answerType: intent.answerType,
      languageCode: language,
      documentReferences: reformatted.documentReferences,
    });
  }

  const totalTime = Date.now() - startTime;

  return {
    answer: finalAnswer,
    answerType: intent.answerType,
    language,
    documentReferences: formatted.documentReferences,
    metadata: {
      retrievalTime,
      generationTime: generated.generationTime,
      totalTime,
      tokensUsed: generated.tokensUsed,
      model: generated.model,
      validationScore: finalValidation.score,
    },
  };
}

/**
 * Build document map from chunks
 */
function buildDocumentMap(chunks: any[]): Map<string, { id: string; name: string; displayTitle?: string; mimeType?: string; size?: number; folderPath?: string }> {
  const map = new Map();

  chunks.forEach(chunk => {
    if (!map.has(chunk.documentId)) {
      map.set(chunk.documentId, {
        id: chunk.documentId,
        name: chunk.documentName || chunk.metadata?.filename || 'Document',
        displayTitle: chunk.metadata?.displayTitle,
        mimeType: chunk.metadata?.mimeType || chunk.mimeType || 'application/octet-stream',
        size: chunk.metadata?.fileSize || chunk.fileSize,
        folderPath: chunk.metadata?.folderPath || chunk.folderPath || '',
      });
    }
  });

  return map;
}

/**
 * Get conversation history (placeholder)
 */
async function getConversationHistory(conversationId: string): Promise<any[]> {
  // TODO: Implement actual history retrieval
  return [];
}

/**
 * Get document count from database
 */
async function getDocumentCount(userId: string): Promise<number> {
  const { PrismaClient } = require('@prisma/client');
  const prisma = new PrismaClient();

  try {
    const count = await prisma.document.count({
      where: {
        userId,
        status: 'completed'
      }
    });
    return count;
  } catch (error) {
    console.error('[getDocumentCount] Error:', error);
    return 0;
  } finally {
    await prisma.$disconnect();
  }
}
