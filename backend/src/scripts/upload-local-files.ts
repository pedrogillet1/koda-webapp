/**
 * Upload Local Files Script
 *
 * This script uploads files from a local folder to the database and generates embeddings.
 *
 * Run with: npx ts-node --transpile-only src/scripts/upload-local-files.ts
 */

import * as fs from 'fs';
import * as path from 'path';
import prisma from '../config/database';
import { extractText } from '../services/textExtraction.service';
import { vectorEmbeddingService } from '../services/vectorEmbedding.service';
import chunkingService from '../services/chunking.service';
import embeddingService from '../services/embedding.service';

const USER_ID = '271a9282-463b-42bd-ac2c-4034ce9d9524'; // localhost@koda.com
const LOCAL_FOLDER = 'C:/Users/pedro/OneDrive/√Årea de Trabalho/trabalhos';
const SUPPORTED_EXTENSIONS = ['.pdf', '.docx', '.xlsx', '.txt', '.pptx'];

interface ProcessingResult {
  filename: string;
  success: boolean;
  error?: string;
  chunksCreated?: number;
}

function getMimeType(filename: string): string {
  const ext = path.extname(filename).toLowerCase();
  const mimeTypes: Record<string, string> = {
    '.pdf': 'application/pdf',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
    '.txt': 'text/plain',
    '.csv': 'text/csv',
    '.html': 'text/html',
  };
  return mimeTypes[ext] || 'application/octet-stream';
}

async function processLocalFile(filePath: string): Promise<ProcessingResult> {
  const filename = path.basename(filePath);
  const result: ProcessingResult = {
    filename,
    success: false,
  };

  try {
    console.log(`\nüìÑ Processing: ${filename}`);

    // Step 1: Read file
    console.log('  üìÇ Reading file...');
    const fileBuffer = fs.readFileSync(filePath);
    const mimeType = getMimeType(filename);
    console.log(`  ‚úÖ File size: ${(fileBuffer.length / 1024).toFixed(1)} KB`);

    // Step 2: Check if document already exists
    const existingDoc = await prisma.document.findFirst({
      where: {
        userId: USER_ID,
        filename: filename,
      }
    });

    let documentId: string;

    if (existingDoc) {
      console.log(`  ‚ÑπÔ∏è  Document exists, updating...`);
      documentId = existingDoc.id;

      // Delete existing chunks
      await prisma.documentChunk.deleteMany({
        where: { documentId }
      });
    } else {
      console.log('  ‚ûï Creating new document record...');
      const newDoc = await prisma.document.create({
        data: {
          userId: USER_ID,
          filename,
          displayTitle: filename,
          mimeType,
          fileSize: fileBuffer.length,
          status: 'processing',
          embeddingsGenerated: false,
          fileHash: 'local-upload',
        }
      });
      documentId = newDoc.id;
    }

    // Step 3: Extract text
    console.log('  üìù Extracting text...');
    const extractionResult = await extractText(fileBuffer, mimeType);
    const extractedText = extractionResult.text;
    if (!extractedText || extractedText.length < 10) {
      throw new Error(`Failed to extract text or text too short (got ${extractedText?.length || 0} chars)`);
    }
    console.log(`  ‚úÖ Extracted ${extractedText.length} characters`);

    // Step 4: Chunk text
    console.log('  üî™ Chunking text...');
    const rawChunks = chunkingService.chunkTextWithOverlap(extractedText, {
      maxChunkSize: 1000,
      overlap: 200
    });
    console.log(`  üìä Raw chunks count: ${rawChunks.length}`);

    const chunks = rawChunks.map((chunk) => ({
      content: chunk.content,
      text: chunk.content, // Some services expect 'text' instead of 'content'
      metadata: {
        chunkIndex: chunk.chunkIndex,
        startChar: chunk.startChar,
        endChar: chunk.endChar,
        filename,
      }
    }));
    console.log(`  ‚úÖ Created ${chunks.length} chunks`);

    // Step 5: Save chunks to database
    console.log('  üíæ Saving chunks to database...');
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      await prisma.documentChunk.create({
        data: {
          documentId,
          text: chunk.content,
          chunkIndex: i,
          startChar: chunk.metadata.startChar,
          endChar: chunk.metadata.endChar,
        }
      });
    }

    // Step 6: Generate embeddings for each chunk
    console.log('  üß† Generating embeddings...');
    const chunksWithEmbeddings = [];
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      try {
        const embeddingResult = await embeddingService.generateEmbedding(chunk.content);
        chunksWithEmbeddings.push({
          ...chunk,
          embedding: embeddingResult.embedding,
        });
        if ((i + 1) % 10 === 0 || i === chunks.length - 1) {
          console.log(`    üìä Generated ${i + 1}/${chunks.length} embeddings`);
        }
      } catch (embError: any) {
        console.error(`    ‚ö†Ô∏è Failed to generate embedding for chunk ${i}: ${embError.message}`);
        // Skip this chunk but continue with others
      }
    }

    // Step 7: Store embeddings in Pinecone
    console.log('  üíæ Storing embeddings in Pinecone...');
    await vectorEmbeddingService.storeDocumentEmbeddings(documentId, chunksWithEmbeddings);

    // Step 8: Update document status
    await prisma.document.update({
      where: { id: documentId },
      data: {
        embeddingsGenerated: true,
        chunksCount: chunks.length,
        status: 'completed',
      }
    });

    result.success = true;
    result.chunksCreated = chunks.length;
    console.log(`  ‚úÖ Document processed successfully!`);

  } catch (error: any) {
    result.error = error.message;
    console.error(`  ‚ùå Error: ${error.message}`);
  }

  return result;
}

async function main() {
  console.log('üöÄ Starting local file upload and embedding generation...\n');
  console.log(`üìÅ Source folder: ${LOCAL_FOLDER}\n`);

  // Get list of files
  const files = fs.readdirSync(LOCAL_FOLDER)
    .filter(f => {
      const ext = path.extname(f).toLowerCase();
      return SUPPORTED_EXTENSIONS.includes(ext) && !fs.statSync(path.join(LOCAL_FOLDER, f)).isDirectory();
    });

  console.log(`Found ${files.length} supported files\n`);

  const results: ProcessingResult[] = [];

  for (const file of files) {
    const filePath = path.join(LOCAL_FOLDER, file);
    const result = await processLocalFile(filePath);
    results.push(result);
  }

  // Summary
  console.log('\n\n========================================');
  console.log('üìä PROCESSING SUMMARY');
  console.log('========================================');

  const successful = results.filter(r => r.success);
  const failed = results.filter(r => !r.success);

  console.log(`‚úÖ Successful: ${successful.length}`);
  console.log(`‚ùå Failed: ${failed.length}`);

  if (successful.length > 0) {
    console.log('\nSuccessful uploads:');
    for (const s of successful) {
      console.log(`  ‚úÖ ${s.filename} (${s.chunksCreated} chunks)`);
    }
  }

  if (failed.length > 0) {
    console.log('\nFailed documents:');
    for (const f of failed) {
      console.log(`  ‚ùå ${f.filename}: ${f.error}`);
    }
  }

  console.log('\n‚ú® Done!');
}

main()
  .catch(console.error)
  .finally(() => prisma.$disconnect());
